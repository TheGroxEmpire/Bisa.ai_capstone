{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-Jwu56ppdXxT"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "CNN_base_mobilenetv2 = MobileNetV2(input_shape = (75, 75, 3), include_top = False, weights = 'imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "LuCWmMcMq_4p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "996\n",
            "248\n"
          ]
        }
      ],
      "source": [
        "for layer in CNN_base_mobilenet.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CNN_mobilenet_v2 = Sequential()\n",
        "CNN_mobilenet_v2.add(BatchNormalization(input_shape = (75, 75, 3)))\n",
        "CNN_mobilenet_v2.add(CNN_base_mobilenetv2)\n",
        "CNN_mobilenet_v2.add(BatchNormalization())\n",
        "CNN_mobilenet_v2.add(GlobalAveragePooling2D())\n",
        "CNN_mobilenet_v2.add(Dropout(0.5))\n",
        "CNN_mobilenet_v2.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "CNN_mobilenet_v2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compilation\n",
        "CNN_mobilenet_v2.compile(optimizer='adam',loss = 'binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Start of counting time\n",
        "start = dt.datetime.now()\n",
        "\n",
        "# Training and validation\n",
        "CNN_mobilenet_history = CNN_mobilenet_v2.fit(training_set, epochs = 25, validation_data = validation_set, callbacks = cb)\n",
        "\n",
        "# End of Time Counting\n",
        "end = dt.datetime.now()\n",
        "time_CNN_mobilenet_v2 = end - start\n",
        "print ('\\nTraining and validation time: ', time_CNN_mobilenet_v2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def configure_for_performance(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=1000)\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "train_ds = configure_for_performance(train_ds)\n",
        "val_ds = configure_for_performance(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " tf.math.truediv_3 (TFOpLamb  (None, 256, 256, 3)      0         \n",
            " da)                                                             \n",
            "                                                                 \n",
            " tf.math.subtract_3 (TFOpLam  (None, 256, 256, 3)      0         \n",
            " bda)                                                            \n",
            "                                                                 \n",
            " mobilenetv2_1.00_224 (Funct  (None, 8, 8, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 8, 8, 1280)        0         \n",
            "                                                                 \n",
            " global_average_pooling2d_3   (None, 1280)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 1281      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,259,265\n",
            "Trainable params: 2,225,153\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(IMG_SHAPE),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "prediction_layer = tf.keras.layers.Dense(1)\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "\n",
        "\n",
        "inputs = tf.keras.Input(shape=(256, 256, 3))\n",
        "x = preprocess_input(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = global_average_layer(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(\n",
        "        optimizer='adam',\n",
        "        loss=tf.keras.losses.mse,\n",
        "        metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "249/249 [==============================] - 59s 228ms/step - loss: 270.3905 - accuracy: 0.0000e+00 - val_loss: 230.2793 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x25685fd5b50>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 33ms/step\n",
            "[[37.351955]]\n"
          ]
        }
      ],
      "source": [
        "img = tf.io.read_file(\"D:\\Grox's Vault\\Laboratory\\Repos\\Bisa.ai_capstone\\Dataset\\TRANCOS_v3\\images\\image-3-000421.jpg\")\n",
        "img = decode_img(img)\n",
        "img = (np.expand_dims(img,0))\n",
        "print(model.predict(img))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('civ6_rl_rllib')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "35965d07ac7af2b36ba550e47a4a1a31903255127ab1256fb052beca2e643834"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
